{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d524d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFrom previous observtions Random Forest has the most accuracy,\\nwe will use it for our final model and improve it further\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "From previous observtions Random Forest has the most accuracy,\n",
    "we will use it for our final model and improve it further\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a9382fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning Random Forest...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=271; total time= 8.2min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=271; total time= 7.2min\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=271; total time= 7.2min\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=282; total time= 6.4min\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=282; total time= 6.7min\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=282; total time= 7.1min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=299; total time=155.7min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=299; total time=107.9min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=299; total time=195.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=252; total time=13.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=252; total time=21.1min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=252; total time=17.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=201; total time=15.4min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=201; total time= 9.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=201; total time= 9.3min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=275; total time=12.9min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=275; total time=13.6min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=275; total time=12.4min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=248; total time=11.7min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=248; total time=11.0min\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=248; total time=10.4min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=291; total time= 8.9min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=291; total time= 9.8min\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=291; total time=74.9min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=261; total time=25.7min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=261; total time=14.2min\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=261; total time=14.2min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=263; total time=10.0min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=263; total time=17.9min\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=263; total time=15.3min\n",
      "\n",
      "Best Hyperparameters: {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 275}\n",
      "\n",
      "Evaluating Tuned Random Forest...\n",
      "Final Accuracy: 0.9719, Precision: 0.9400, Recall: 0.9621, Time: 54438.64s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Result/features_used.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "start_time = time.time()\n",
    "\n",
    "# Top 20 features + Label\n",
    "cols = [\"Bwd Packet Length Std\", \"Flow Bytes/s\", \"Total Length of Fwd Packets\", \"Fwd Packet Length Std\",\n",
    "        \"Flow IAT Std\", \"Flow IAT Min\", \"Fwd IAT Total\", \"Flow Duration\", \"Bwd Packet Length Max\",\n",
    "        \"Flow IAT Max\", \"Flow IAT Mean\", \"Total Length of Bwd Packets\", \"Fwd Packet Length Min\",\n",
    "        \"Bwd Packet Length Mean\", \"Flow Packets/s\", \"Fwd Packet Length Mean\", \"Total Backward Packets\",\n",
    "        \"Fwd Packet Length Max\", \"Total Fwd Packets\", \"Bwd Packet Length Min\", 'Label']\n",
    "\n",
    "data_file = \"merged.csv\"\n",
    "\n",
    "df = pd.read_csv(data_file, usecols=cols)\n",
    "df = df.fillna(0)\n",
    "df['Label'] = df['Label'].apply(lambda x: 1 if x == \"BENIGN\" else 0)\n",
    "\n",
    "\n",
    "# Feature and label split\n",
    "X = df.drop(\"Label\", axis=1)\n",
    "y = df[\"Label\"]\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(200, 300),\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=42, class_weight='balanced')\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    scoring='accuracy',\n",
    "    cv=cv,\n",
    "    random_state=42,\n",
    "    n_jobs=1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "print(\"\\nTuning Random Forest...\")\n",
    "search.fit(X, y)\n",
    "\n",
    "best_model = search.best_estimator_\n",
    "print(\"\\nBest Hyperparameters:\", search.best_params_)\n",
    "\n",
    "# Metrics for evaluation\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average='macro'),\n",
    "    'recall': make_scorer(recall_score, average='macro')\n",
    "}\n",
    "\n",
    "print(\"\\nEvaluating Tuned Random Forest...\")\n",
    "results = cross_validate(best_model, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "mean_acc = np.mean(results[\"test_accuracy\"])\n",
    "mean_prec = np.mean(results[\"test_precision\"])\n",
    "mean_rec = np.mean(results[\"test_recall\"])\n",
    "duration = round(time.time() - start_time, 2)\n",
    "\n",
    "print(f\"Final Accuracy: {mean_acc:.4f}, Precision: {mean_prec:.4f}, Recall: {mean_rec:.4f}, Time: {duration}s\")\n",
    "\n",
    "# Save results to CSV\n",
    "with open(\"Result/final_random_forest_results.csv\", \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Tuned Random Forest\", round(mean_acc, 4), round(mean_prec, 4), round(mean_rec, 4), duration])\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(best_model, \"Result/Network_Anomaly_Detection_rf.pkl\")\n",
    "feature_list = X.columns.tolist()\n",
    "joblib.dump(feature_list, \"Result/features_used.pkl\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
